{"ast":null,"code":"\"use strict\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n      label: 0,\n      sent: function () {\n        if (t[0] & 1) throw t[1];\n        return t[1];\n      },\n      trys: [],\n      ops: []\n    },\n    f,\n    y,\n    t,\n    g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n        case 7:\n          op = _.ops.pop();\n          _.trys.pop();\n          continue;\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n            _.ops.push(op);\n            break;\n          }\n          if (t[2]) _.ops.pop();\n          _.trys.pop();\n          continue;\n      }\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar path = require(\"path\");\nvar ProgressBar = require(\"progress\");\nvar tensorboard_1 = require(\"./tensorboard\");\n// A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\nexports.progressBarHelper = {\n  ProgressBar: ProgressBar,\n  log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\nvar ProgbarLogger = /** @class */function (_super) {\n  __extends(ProgbarLogger, _super);\n  /**\n   * Construtor of LoggingCallback.\n   */\n  function ProgbarLogger() {\n    var _this = _super.call(this, {\n      onTrainBegin: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var samples, batchSize, steps;\n          return __generator(this, function (_a) {\n            samples = this.params.samples;\n            batchSize = this.params.batchSize;\n            steps = this.params.steps;\n            if (samples != null || steps != null) {\n              this.numTrainBatchesPerEpoch = samples != null ? Math.ceil(samples / batchSize) : steps;\n            } else {\n              // Undetermined number of batches per epoch, e.g., due to\n              // `fitDataset()` without `batchesPerEpoch`.\n              this.numTrainBatchesPerEpoch = 0;\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onEpochBegin: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            exports.progressBarHelper.log(\"Epoch \" + (epoch + 1) + \" / \" + this.params.epochs);\n            this.currentEpochBegin = tfjs_1.util.now();\n            this.epochDurationMillis = null;\n            this.usPerStep = null;\n            this.batchesInLatestEpoch = 0;\n            this.terminalWidth = process.stderr.columns;\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var maxMetricsStringLength, tickTokens;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                this.batchesInLatestEpoch++;\n                if (batch === 0) {\n                  this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                    width: Math.floor(0.5 * this.terminalWidth),\n                    total: this.numTrainBatchesPerEpoch + 1,\n                    head: \">\",\n                    renderThrottle: this.RENDER_THROTTLE_MS\n                  });\n                }\n                maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                tickTokens = {\n                  placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                };\n                if (this.numTrainBatchesPerEpoch === 0) {\n                  // Undetermined number of batches per epoch.\n                  this.progressBar.tick(0, tickTokens);\n                } else {\n                  this.progressBar.tick(tickTokens);\n                }\n                return [4 /*yield*/, tfjs_1.nextFrame()];\n              case 1:\n                _a.sent();\n                if (batch === this.numTrainBatchesPerEpoch - 1) {\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.params.samples != null ? this.epochDurationMillis / this.params.samples * 1e3 : this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n                return [2 /*return*/];\n            }\n          });\n        });\n      },\n\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var lossesAndMetricsString;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                if (this.epochDurationMillis == null) {\n                  // In cases where the number of batches per epoch is not determined,\n                  // the calculation of the per-step duration is done at the end of the\n                  // epoch. N.B., this includes the time spent on validation.\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n                this.progressBar.tick({\n                  placeholderForLossesAndMetrics: ''\n                });\n                lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                exports.progressBarHelper.log(this.epochDurationMillis.toFixed(0) + \"ms \" + (this.usPerStep.toFixed(0) + \"us/step - \") + (\"\" + lossesAndMetricsString));\n                return [4 /*yield*/, tfjs_1.nextFrame()];\n              case 1:\n                _a.sent();\n                return [2 /*return*/];\n            }\n          });\n        });\n      }\n    }) || this;\n    _this.RENDER_THROTTLE_MS = 50;\n    return _this;\n  }\n  ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n    var metricsContent = '';\n    var keys = Object.keys(logs).sort();\n    for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n      var key = keys_1[_i];\n      if (this.isFieldRelevant(key)) {\n        var value = logs[key];\n        metricsContent += key + \"=\" + getSuccinctNumberDisplay(value) + \" \";\n      }\n    }\n    if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n      // Cut off metrics strings that are too long to avoid new lines being\n      // constantly created.\n      metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n    }\n    return metricsContent;\n  };\n  ProgbarLogger.prototype.isFieldRelevant = function (key) {\n    return key !== 'batch' && key !== 'size';\n  };\n  return ProgbarLogger;\n}(tfjs_1.CustomCallback);\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\nfunction getSuccinctNumberDisplay(x) {\n  var decimalPlaces = getDisplayDecimalPlaces(x);\n  return decimalPlaces > MAX_NUM_DECIMAL_PLACES ? x.toExponential(BASE_NUM_DIGITS) : x.toFixed(decimalPlaces);\n}\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\nfunction getDisplayDecimalPlaces(x) {\n  if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n    return BASE_NUM_DIGITS;\n  } else {\n    return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n  }\n}\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\nvar TensorBoardCallback = /** @class */function (_super) {\n  __extends(TensorBoardCallback, _super);\n  function TensorBoardCallback(logdir, args) {\n    if (logdir === void 0) {\n      logdir = './logs';\n    }\n    var _this = _super.call(this, {\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.batchesSeen++;\n            if (this.args.updateFreq !== 'epoch') {\n              this.logMetrics(logs, 'batch_', this.batchesSeen);\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.logMetrics(logs, 'epoch_', epoch + 1);\n            if (this.args.histogramFreq > 0 && epoch % this.args.histogramFreq === 0) {\n              this.logWeights(epoch);\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onTrainEnd: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            if (this.trainWriter != null) {\n              this.trainWriter.flush();\n            }\n            if (this.valWriter != null) {\n              this.valWriter.flush();\n            }\n            return [2 /*return*/];\n          });\n        });\n      }\n    }) || this;\n    _this.logdir = logdir;\n    _this.model = null;\n    _this.args = args == null ? {} : args;\n    if (_this.args.updateFreq == null) {\n      _this.args.updateFreq = 'epoch';\n    }\n    tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () {\n      return \"Expected updateFreq to be 'batch' or 'epoch', but got \" + (\"\" + _this.args.updateFreq);\n    });\n    if (_this.args.histogramFreq == null) {\n      _this.args.histogramFreq = 0;\n    }\n    tfjs_1.util.assert(Number.isInteger(_this.args.histogramFreq) && _this.args.histogramFreq >= 0, function () {\n      return \"Expected histogramFreq to be a positive integer, but got \" + (\"\" + _this.args.histogramFreq);\n    });\n    _this.batchesSeen = 0;\n    return _this;\n  }\n  TensorBoardCallback.prototype.setModel = function (model) {\n    // This method is inherited from BaseCallback. To avoid cyclical imports,\n    // that class uses Container instead of LayersModel, and uses a run-time\n    // check to make sure the model is a LayersModel.\n    // Since this subclass isn't imported by tfjs-layers, we can safely use type\n    // the parameter as a LayersModel.\n    this.model = model;\n  };\n  TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n    for (var key in logs) {\n      if (key === 'batch' || key === 'size' || key === 'num_steps') {\n        continue;\n      }\n      var VAL_PREFIX = 'val_';\n      if (key.startsWith(VAL_PREFIX)) {\n        this.ensureValWriterCreated();\n        var scalarName = prefix + key.slice(VAL_PREFIX.length);\n        this.valWriter.scalar(scalarName, logs[key], step);\n      } else {\n        this.ensureTrainWriterCreated();\n        this.trainWriter.scalar(\"\" + prefix + key, logs[key], step);\n      }\n    }\n  };\n  TensorBoardCallback.prototype.logWeights = function (step) {\n    for (var _i = 0, _a = this.model.weights; _i < _a.length; _i++) {\n      var weights = _a[_i];\n      this.trainWriter.histogram(weights.name, weights.read(), step);\n    }\n  };\n  TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n    this.trainWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'train'));\n  };\n  TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n    this.valWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'val'));\n  };\n  return TensorBoardCallback;\n}(tfjs_1.CustomCallback);\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n *\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\nfunction tensorBoard(logdir, args) {\n  if (logdir === void 0) {\n    logdir = './logs';\n  }\n  return new TensorBoardCallback(logdir, args);\n}\nexports.tensorBoard = tensorBoard;","map":{"version":3,"names":["__extends","extendStatics","d","b","Object","setPrototypeOf","__proto__","Array","p","hasOwnProperty","__","constructor","prototype","create","__awaiter","thisArg","_arguments","P","generator","Promise","resolve","reject","fulfilled","value","step","next","e","rejected","result","done","then","apply","__generator","body","_","label","sent","t","trys","ops","f","y","g","verb","Symbol","iterator","n","v","op","TypeError","call","pop","length","push","defineProperty","exports","tfjs_1","require","path","ProgressBar","tensorboard_1","progressBarHelper","log","console","ProgbarLogger","_super","_this","onTrainBegin","logs","samples","batchSize","steps","_a","params","numTrainBatchesPerEpoch","Math","ceil","onEpochBegin","epoch","epochs","currentEpochBegin","util","now","epochDurationMillis","usPerStep","batchesInLatestEpoch","terminalWidth","process","stderr","columns","onBatchEnd","batch","maxMetricsStringLength","tickTokens","progressBar","width","floor","total","head","renderThrottle","RENDER_THROTTLE_MS","placeholderForLossesAndMetrics","formatLogsAsMetricsContent","tick","nextFrame","onEpochEnd","lossesAndMetricsString","toFixed","maxMetricsLength","metricsContent","keys","sort","_i","keys_1","key","isFieldRelevant","getSuccinctNumberDisplay","slice","CustomCallback","BASE_NUM_DIGITS","MAX_NUM_DECIMAL_PLACES","x","decimalPlaces","getDisplayDecimalPlaces","toExponential","Number","isFinite","log10","abs","TensorBoardCallback","logdir","args","batchesSeen","updateFreq","logMetrics","histogramFreq","logWeights","onTrainEnd","trainWriter","flush","valWriter","model","assert","indexOf","isInteger","setModel","prefix","VAL_PREFIX","startsWith","ensureValWriterCreated","scalarName","scalar","ensureTrainWriterCreated","weights","histogram","name","read","summaryFileWriter","join","tensorBoard"],"sources":["C:/Users/ACER/node_modules/@tensorflow/tfjs-node/dist/callbacks.js"],"sourcesContent":["\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar path = require(\"path\");\nvar ProgressBar = require(\"progress\");\nvar tensorboard_1 = require(\"./tensorboard\");\n// A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\nexports.progressBarHelper = {\n    ProgressBar: ProgressBar,\n    log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\nvar ProgbarLogger = /** @class */ (function (_super) {\n    __extends(ProgbarLogger, _super);\n    /**\n     * Construtor of LoggingCallback.\n     */\n    function ProgbarLogger() {\n        var _this = _super.call(this, {\n            onTrainBegin: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                var samples, batchSize, steps;\n                return __generator(this, function (_a) {\n                    samples = this.params.samples;\n                    batchSize = this.params.batchSize;\n                    steps = this.params.steps;\n                    if (samples != null || steps != null) {\n                        this.numTrainBatchesPerEpoch =\n                            samples != null ? Math.ceil(samples / batchSize) : steps;\n                    }\n                    else {\n                        // Undetermined number of batches per epoch, e.g., due to\n                        // `fitDataset()` without `batchesPerEpoch`.\n                        this.numTrainBatchesPerEpoch = 0;\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochBegin: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    exports.progressBarHelper.log(\"Epoch \" + (epoch + 1) + \" / \" + this.params.epochs);\n                    this.currentEpochBegin = tfjs_1.util.now();\n                    this.epochDurationMillis = null;\n                    this.usPerStep = null;\n                    this.batchesInLatestEpoch = 0;\n                    this.terminalWidth = process.stderr.columns;\n                    return [2 /*return*/];\n                });\n            }); },\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var maxMetricsStringLength, tickTokens;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            this.batchesInLatestEpoch++;\n                            if (batch === 0) {\n                                this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                                    width: Math.floor(0.5 * this.terminalWidth),\n                                    total: this.numTrainBatchesPerEpoch + 1,\n                                    head: \">\",\n                                    renderThrottle: this.RENDER_THROTTLE_MS\n                                });\n                            }\n                            maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                            tickTokens = {\n                                placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                            };\n                            if (this.numTrainBatchesPerEpoch === 0) {\n                                // Undetermined number of batches per epoch.\n                                this.progressBar.tick(0, tickTokens);\n                            }\n                            else {\n                                this.progressBar.tick(tickTokens);\n                            }\n                            return [4 /*yield*/, tfjs_1.nextFrame()];\n                        case 1:\n                            _a.sent();\n                            if (batch === this.numTrainBatchesPerEpoch - 1) {\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep = this.params.samples != null ?\n                                    this.epochDurationMillis / this.params.samples * 1e3 :\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var lossesAndMetricsString;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            if (this.epochDurationMillis == null) {\n                                // In cases where the number of batches per epoch is not determined,\n                                // the calculation of the per-step duration is done at the end of the\n                                // epoch. N.B., this includes the time spent on validation.\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep =\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            this.progressBar.tick({ placeholderForLossesAndMetrics: '' });\n                            lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                            exports.progressBarHelper.log(this.epochDurationMillis.toFixed(0) + \"ms \" +\n                                (this.usPerStep.toFixed(0) + \"us/step - \") +\n                                (\"\" + lossesAndMetricsString));\n                            return [4 /*yield*/, tfjs_1.nextFrame()];\n                        case 1:\n                            _a.sent();\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n        }) || this;\n        _this.RENDER_THROTTLE_MS = 50;\n        return _this;\n    }\n    ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n        var metricsContent = '';\n        var keys = Object.keys(logs).sort();\n        for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n            var key = keys_1[_i];\n            if (this.isFieldRelevant(key)) {\n                var value = logs[key];\n                metricsContent += key + \"=\" + getSuccinctNumberDisplay(value) + \" \";\n            }\n        }\n        if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n            // Cut off metrics strings that are too long to avoid new lines being\n            // constantly created.\n            metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n        }\n        return metricsContent;\n    };\n    ProgbarLogger.prototype.isFieldRelevant = function (key) {\n        return key !== 'batch' && key !== 'size';\n    };\n    return ProgbarLogger;\n}(tfjs_1.CustomCallback));\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\nfunction getSuccinctNumberDisplay(x) {\n    var decimalPlaces = getDisplayDecimalPlaces(x);\n    return decimalPlaces > MAX_NUM_DECIMAL_PLACES ?\n        x.toExponential(BASE_NUM_DIGITS) :\n        x.toFixed(decimalPlaces);\n}\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\nfunction getDisplayDecimalPlaces(x) {\n    if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n        return BASE_NUM_DIGITS;\n    }\n    else {\n        return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n    }\n}\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\nvar TensorBoardCallback = /** @class */ (function (_super) {\n    __extends(TensorBoardCallback, _super);\n    function TensorBoardCallback(logdir, args) {\n        if (logdir === void 0) { logdir = './logs'; }\n        var _this = _super.call(this, {\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.batchesSeen++;\n                    if (this.args.updateFreq !== 'epoch') {\n                        this.logMetrics(logs, 'batch_', this.batchesSeen);\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.logMetrics(logs, 'epoch_', epoch + 1);\n                    if (this.args.histogramFreq > 0 &&\n                        epoch % this.args.histogramFreq === 0) {\n                        this.logWeights(epoch);\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onTrainEnd: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    if (this.trainWriter != null) {\n                        this.trainWriter.flush();\n                    }\n                    if (this.valWriter != null) {\n                        this.valWriter.flush();\n                    }\n                    return [2 /*return*/];\n                });\n            }); }\n        }) || this;\n        _this.logdir = logdir;\n        _this.model = null;\n        _this.args = args == null ? {} : args;\n        if (_this.args.updateFreq == null) {\n            _this.args.updateFreq = 'epoch';\n        }\n        tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () { return \"Expected updateFreq to be 'batch' or 'epoch', but got \" +\n            (\"\" + _this.args.updateFreq); });\n        if (_this.args.histogramFreq == null) {\n            _this.args.histogramFreq = 0;\n        }\n        tfjs_1.util.assert(Number.isInteger(_this.args.histogramFreq) &&\n            _this.args.histogramFreq >= 0, function () { return \"Expected histogramFreq to be a positive integer, but got \" +\n            (\"\" + _this.args.histogramFreq); });\n        _this.batchesSeen = 0;\n        return _this;\n    }\n    TensorBoardCallback.prototype.setModel = function (model) {\n        // This method is inherited from BaseCallback. To avoid cyclical imports,\n        // that class uses Container instead of LayersModel, and uses a run-time\n        // check to make sure the model is a LayersModel.\n        // Since this subclass isn't imported by tfjs-layers, we can safely use type\n        // the parameter as a LayersModel.\n        this.model = model;\n    };\n    TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n        for (var key in logs) {\n            if (key === 'batch' || key === 'size' || key === 'num_steps') {\n                continue;\n            }\n            var VAL_PREFIX = 'val_';\n            if (key.startsWith(VAL_PREFIX)) {\n                this.ensureValWriterCreated();\n                var scalarName = prefix + key.slice(VAL_PREFIX.length);\n                this.valWriter.scalar(scalarName, logs[key], step);\n            }\n            else {\n                this.ensureTrainWriterCreated();\n                this.trainWriter.scalar(\"\" + prefix + key, logs[key], step);\n            }\n        }\n    };\n    TensorBoardCallback.prototype.logWeights = function (step) {\n        for (var _i = 0, _a = this.model.weights; _i < _a.length; _i++) {\n            var weights = _a[_i];\n            this.trainWriter.histogram(weights.name, weights.read(), step);\n        }\n    };\n    TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n        this.trainWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'train'));\n    };\n    TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n        this.valWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'val'));\n    };\n    return TensorBoardCallback;\n}(tfjs_1.CustomCallback));\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n *\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\nfunction tensorBoard(logdir, args) {\n    if (logdir === void 0) { logdir = './logs'; }\n    return new TensorBoardCallback(logdir, args);\n}\nexports.tensorBoard = tensorBoard;\n"],"mappings":"AAAA,YAAY;;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIA,SAAS,GAAI,IAAI,IAAI,IAAI,CAACA,SAAS,IAAM,YAAY;EACrD,IAAIC,aAAa,GAAG,SAAAA,CAAUC,CAAC,EAAEC,CAAC,EAAE;IAChCF,aAAa,GAAGG,MAAM,CAACC,cAAc,IAChC;MAAEC,SAAS,EAAE;IAAG,CAAC,YAAYC,KAAK,IAAI,UAAUL,CAAC,EAAEC,CAAC,EAAE;MAAED,CAAC,CAACI,SAAS,GAAGH,CAAC;IAAE,CAAE,IAC5E,UAAUD,CAAC,EAAEC,CAAC,EAAE;MAAE,KAAK,IAAIK,CAAC,IAAIL,CAAC,EAAE,IAAIA,CAAC,CAACM,cAAc,CAACD,CAAC,CAAC,EAAEN,CAAC,CAACM,CAAC,CAAC,GAAGL,CAAC,CAACK,CAAC,CAAC;IAAE,CAAC;IAC9E,OAAOP,aAAa,CAACC,CAAC,EAAEC,CAAC,CAAC;EAC9B,CAAC;EACD,OAAO,UAAUD,CAAC,EAAEC,CAAC,EAAE;IACnBF,aAAa,CAACC,CAAC,EAAEC,CAAC,CAAC;IACnB,SAASO,EAAEA,CAAA,EAAG;MAAE,IAAI,CAACC,WAAW,GAAGT,CAAC;IAAE;IACtCA,CAAC,CAACU,SAAS,GAAGT,CAAC,KAAK,IAAI,GAAGC,MAAM,CAACS,MAAM,CAACV,CAAC,CAAC,IAAIO,EAAE,CAACE,SAAS,GAAGT,CAAC,CAACS,SAAS,EAAE,IAAIF,EAAE,CAAC,CAAC,CAAC;EACxF,CAAC;AACL,CAAC,CAAE,CAAC;AACJ,IAAII,SAAS,GAAI,IAAI,IAAI,IAAI,CAACA,SAAS,IAAK,UAAUC,OAAO,EAAEC,UAAU,EAAEC,CAAC,EAAEC,SAAS,EAAE;EACrF,OAAO,KAAKD,CAAC,KAAKA,CAAC,GAAGE,OAAO,CAAC,EAAE,UAAUC,OAAO,EAAEC,MAAM,EAAE;IACvD,SAASC,SAASA,CAACC,KAAK,EAAE;MAAE,IAAI;QAAEC,IAAI,CAACN,SAAS,CAACO,IAAI,CAACF,KAAK,CAAC,CAAC;MAAE,CAAC,CAAC,OAAOG,CAAC,EAAE;QAAEL,MAAM,CAACK,CAAC,CAAC;MAAE;IAAE;IAC1F,SAASC,QAAQA,CAACJ,KAAK,EAAE;MAAE,IAAI;QAAEC,IAAI,CAACN,SAAS,CAAC,OAAO,CAAC,CAACK,KAAK,CAAC,CAAC;MAAE,CAAC,CAAC,OAAOG,CAAC,EAAE;QAAEL,MAAM,CAACK,CAAC,CAAC;MAAE;IAAE;IAC7F,SAASF,IAAIA,CAACI,MAAM,EAAE;MAAEA,MAAM,CAACC,IAAI,GAAGT,OAAO,CAACQ,MAAM,CAACL,KAAK,CAAC,GAAG,IAAIN,CAAC,CAAC,UAAUG,OAAO,EAAE;QAAEA,OAAO,CAACQ,MAAM,CAACL,KAAK,CAAC;MAAE,CAAC,CAAC,CAACO,IAAI,CAACR,SAAS,EAAEK,QAAQ,CAAC;IAAE;IAC9IH,IAAI,CAAC,CAACN,SAAS,GAAGA,SAAS,CAACa,KAAK,CAAChB,OAAO,EAAEC,UAAU,IAAI,EAAE,CAAC,EAAES,IAAI,CAAC,CAAC,CAAC;EACzE,CAAC,CAAC;AACN,CAAC;AACD,IAAIO,WAAW,GAAI,IAAI,IAAI,IAAI,CAACA,WAAW,IAAK,UAAUjB,OAAO,EAAEkB,IAAI,EAAE;EACrE,IAAIC,CAAC,GAAG;MAAEC,KAAK,EAAE,CAAC;MAAEC,IAAI,EAAE,SAAAA,CAAA,EAAW;QAAE,IAAIC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,MAAMA,CAAC,CAAC,CAAC,CAAC;QAAE,OAAOA,CAAC,CAAC,CAAC,CAAC;MAAE,CAAC;MAAEC,IAAI,EAAE,EAAE;MAAEC,GAAG,EAAE;IAAG,CAAC;IAAEC,CAAC;IAAEC,CAAC;IAAEJ,CAAC;IAAEK,CAAC;EAChH,OAAOA,CAAC,GAAG;IAAEjB,IAAI,EAAEkB,IAAI,CAAC,CAAC,CAAC;IAAE,OAAO,EAAEA,IAAI,CAAC,CAAC,CAAC;IAAE,QAAQ,EAAEA,IAAI,CAAC,CAAC;EAAE,CAAC,EAAE,OAAOC,MAAM,KAAK,UAAU,KAAKF,CAAC,CAACE,MAAM,CAACC,QAAQ,CAAC,GAAG,YAAW;IAAE,OAAO,IAAI;EAAE,CAAC,CAAC,EAAEH,CAAC;EACxJ,SAASC,IAAIA,CAACG,CAAC,EAAE;IAAE,OAAO,UAAUC,CAAC,EAAE;MAAE,OAAOvB,IAAI,CAAC,CAACsB,CAAC,EAAEC,CAAC,CAAC,CAAC;IAAE,CAAC;EAAE;EACjE,SAASvB,IAAIA,CAACwB,EAAE,EAAE;IACd,IAAIR,CAAC,EAAE,MAAM,IAAIS,SAAS,CAAC,iCAAiC,CAAC;IAC7D,OAAOf,CAAC,EAAE,IAAI;MACV,IAAIM,CAAC,GAAG,CAAC,EAAEC,CAAC,KAAKJ,CAAC,GAAGW,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,GAAGP,CAAC,CAAC,QAAQ,CAAC,GAAGO,EAAE,CAAC,CAAC,CAAC,GAAGP,CAAC,CAAC,OAAO,CAAC,KAAK,CAACJ,CAAC,GAAGI,CAAC,CAAC,QAAQ,CAAC,KAAKJ,CAAC,CAACa,IAAI,CAACT,CAAC,CAAC,EAAE,CAAC,CAAC,GAAGA,CAAC,CAAChB,IAAI,CAAC,IAAI,CAAC,CAACY,CAAC,GAAGA,CAAC,CAACa,IAAI,CAACT,CAAC,EAAEO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAEnB,IAAI,EAAE,OAAOQ,CAAC;MAC5J,IAAII,CAAC,GAAG,CAAC,EAAEJ,CAAC,EAAEW,EAAE,GAAG,CAACA,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAEX,CAAC,CAACd,KAAK,CAAC;MACvC,QAAQyB,EAAE,CAAC,CAAC,CAAC;QACT,KAAK,CAAC;QAAE,KAAK,CAAC;UAAEX,CAAC,GAAGW,EAAE;UAAE;QACxB,KAAK,CAAC;UAAEd,CAAC,CAACC,KAAK,EAAE;UAAE,OAAO;YAAEZ,KAAK,EAAEyB,EAAE,CAAC,CAAC,CAAC;YAAEnB,IAAI,EAAE;UAAM,CAAC;QACvD,KAAK,CAAC;UAAEK,CAAC,CAACC,KAAK,EAAE;UAAEM,CAAC,GAAGO,EAAE,CAAC,CAAC,CAAC;UAAEA,EAAE,GAAG,CAAC,CAAC,CAAC;UAAE;QACxC,KAAK,CAAC;UAAEA,EAAE,GAAGd,CAAC,CAACK,GAAG,CAACY,GAAG,CAAC,CAAC;UAAEjB,CAAC,CAACI,IAAI,CAACa,GAAG,CAAC,CAAC;UAAE;QACxC;UACI,IAAI,EAAEd,CAAC,GAAGH,CAAC,CAACI,IAAI,EAAED,CAAC,GAAGA,CAAC,CAACe,MAAM,GAAG,CAAC,IAAIf,CAAC,CAACA,CAAC,CAACe,MAAM,GAAG,CAAC,CAAC,CAAC,KAAKJ,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,IAAIA,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;YAAEd,CAAC,GAAG,CAAC;YAAE;UAAU;UAC3G,IAAIc,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAACX,CAAC,IAAKW,EAAE,CAAC,CAAC,CAAC,GAAGX,CAAC,CAAC,CAAC,CAAC,IAAIW,EAAE,CAAC,CAAC,CAAC,GAAGX,CAAC,CAAC,CAAC,CAAE,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGa,EAAE,CAAC,CAAC,CAAC;YAAE;UAAO;UACrF,IAAIA,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,IAAId,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC;YAAEA,CAAC,GAAGW,EAAE;YAAE;UAAO;UACpE,IAAIX,CAAC,IAAIH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC;YAAEH,CAAC,CAACK,GAAG,CAACc,IAAI,CAACL,EAAE,CAAC;YAAE;UAAO;UAClE,IAAIX,CAAC,CAAC,CAAC,CAAC,EAAEH,CAAC,CAACK,GAAG,CAACY,GAAG,CAAC,CAAC;UACrBjB,CAAC,CAACI,IAAI,CAACa,GAAG,CAAC,CAAC;UAAE;MACtB;MACAH,EAAE,GAAGf,IAAI,CAACiB,IAAI,CAACnC,OAAO,EAAEmB,CAAC,CAAC;IAC9B,CAAC,CAAC,OAAOR,CAAC,EAAE;MAAEsB,EAAE,GAAG,CAAC,CAAC,EAAEtB,CAAC,CAAC;MAAEe,CAAC,GAAG,CAAC;IAAE,CAAC,SAAS;MAAED,CAAC,GAAGH,CAAC,GAAG,CAAC;IAAE;IACzD,IAAIW,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,MAAMA,EAAE,CAAC,CAAC,CAAC;IAAE,OAAO;MAAEzB,KAAK,EAAEyB,EAAE,CAAC,CAAC,CAAC,GAAGA,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;MAAEnB,IAAI,EAAE;IAAK,CAAC;EACpF;AACJ,CAAC;AACDzB,MAAM,CAACkD,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEhC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7D,IAAIiC,MAAM,GAAGC,OAAO,CAAC,kBAAkB,CAAC;AACxC,IAAIC,IAAI,GAAGD,OAAO,CAAC,MAAM,CAAC;AAC1B,IAAIE,WAAW,GAAGF,OAAO,CAAC,UAAU,CAAC;AACrC,IAAIG,aAAa,GAAGH,OAAO,CAAC,eAAe,CAAC;AAC5C;AACA;AACA;AACAF,OAAO,CAACM,iBAAiB,GAAG;EACxBF,WAAW,EAAEA,WAAW;EACxBG,GAAG,EAAEC,OAAO,CAACD;AACjB,CAAC;AACD;AACA;AACA;AACA,IAAIE,aAAa,GAAG,aAAe,UAAUC,MAAM,EAAE;EACjDjE,SAAS,CAACgE,aAAa,EAAEC,MAAM,CAAC;EAChC;AACJ;AACA;EACI,SAASD,aAAaA,CAAA,EAAG;IACrB,IAAIE,KAAK,GAAGD,MAAM,CAACf,IAAI,CAAC,IAAI,EAAE;MAC1BiB,YAAY,EAAE,SAAAA,CAAUC,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UAChF,IAAIG,OAAO,EAAEC,SAAS,EAAEC,KAAK;UAC7B,OAAOvC,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnCH,OAAO,GAAG,IAAI,CAACI,MAAM,CAACJ,OAAO;YAC7BC,SAAS,GAAG,IAAI,CAACG,MAAM,CAACH,SAAS;YACjCC,KAAK,GAAG,IAAI,CAACE,MAAM,CAACF,KAAK;YACzB,IAAIF,OAAO,IAAI,IAAI,IAAIE,KAAK,IAAI,IAAI,EAAE;cAClC,IAAI,CAACG,uBAAuB,GACxBL,OAAO,IAAI,IAAI,GAAGM,IAAI,CAACC,IAAI,CAACP,OAAO,GAAGC,SAAS,CAAC,GAAGC,KAAK;YAChE,CAAC,MACI;cACD;cACA;cACA,IAAI,CAACG,uBAAuB,GAAG,CAAC;YACpC;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLG,YAAY,EAAE,SAAAA,CAAUC,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACvF,OAAOlC,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnCjB,OAAO,CAACM,iBAAiB,CAACC,GAAG,CAAC,QAAQ,IAAIgB,KAAK,GAAG,CAAC,CAAC,GAAG,KAAK,GAAG,IAAI,CAACL,MAAM,CAACM,MAAM,CAAC;YAClF,IAAI,CAACC,iBAAiB,GAAGxB,MAAM,CAACyB,IAAI,CAACC,GAAG,CAAC,CAAC;YAC1C,IAAI,CAACC,mBAAmB,GAAG,IAAI;YAC/B,IAAI,CAACC,SAAS,GAAG,IAAI;YACrB,IAAI,CAACC,oBAAoB,GAAG,CAAC;YAC7B,IAAI,CAACC,aAAa,GAAGC,OAAO,CAACC,MAAM,CAACC,OAAO;YAC3C,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLC,UAAU,EAAE,SAAAA,CAAUC,KAAK,EAAEvB,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,IAAI0B,sBAAsB,EAAEC,UAAU;UACtC,OAAO7D,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnC,QAAQA,EAAE,CAACrC,KAAK;cACZ,KAAK,CAAC;gBACF,IAAI,CAACkD,oBAAoB,EAAE;gBAC3B,IAAIM,KAAK,KAAK,CAAC,EAAE;kBACb,IAAI,CAACG,WAAW,GAAG,IAAIvC,OAAO,CAACM,iBAAiB,CAACF,WAAW,CAAC,+CAA+C,EAAE;oBAC1GoC,KAAK,EAAEpB,IAAI,CAACqB,KAAK,CAAC,GAAG,GAAG,IAAI,CAACV,aAAa,CAAC;oBAC3CW,KAAK,EAAE,IAAI,CAACvB,uBAAuB,GAAG,CAAC;oBACvCwB,IAAI,EAAE,GAAG;oBACTC,cAAc,EAAE,IAAI,CAACC;kBACzB,CAAC,CAAC;gBACN;gBACAR,sBAAsB,GAAGjB,IAAI,CAACqB,KAAK,CAAC,IAAI,CAACV,aAAa,GAAG,GAAG,GAAG,EAAE,CAAC;gBAClEO,UAAU,GAAG;kBACTQ,8BAA8B,EAAE,IAAI,CAACC,0BAA0B,CAAClC,IAAI,EAAEwB,sBAAsB;gBAChG,CAAC;gBACD,IAAI,IAAI,CAAClB,uBAAuB,KAAK,CAAC,EAAE;kBACpC;kBACA,IAAI,CAACoB,WAAW,CAACS,IAAI,CAAC,CAAC,EAAEV,UAAU,CAAC;gBACxC,CAAC,MACI;kBACD,IAAI,CAACC,WAAW,CAACS,IAAI,CAACV,UAAU,CAAC;gBACrC;gBACA,OAAO,CAAC,CAAC,CAAC,WAAWrC,MAAM,CAACgD,SAAS,CAAC,CAAC,CAAC;cAC5C,KAAK,CAAC;gBACFhC,EAAE,CAACpC,IAAI,CAAC,CAAC;gBACT,IAAIuD,KAAK,KAAK,IAAI,CAACjB,uBAAuB,GAAG,CAAC,EAAE;kBAC5C,IAAI,CAACS,mBAAmB,GAAG3B,MAAM,CAACyB,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,IAAI,CAACF,iBAAiB;kBACrE,IAAI,CAACI,SAAS,GAAG,IAAI,CAACX,MAAM,CAACJ,OAAO,IAAI,IAAI,GACxC,IAAI,CAACc,mBAAmB,GAAG,IAAI,CAACV,MAAM,CAACJ,OAAO,GAAG,GAAG,GACpD,IAAI,CAACc,mBAAmB,GAAG,IAAI,CAACE,oBAAoB,GAAG,GAAG;gBAClE;gBACA,OAAO,CAAC,CAAC,CAAC,WAAW;YAC7B;UACJ,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLoB,UAAU,EAAE,SAAAA,CAAU3B,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,IAAIwC,sBAAsB;UAC1B,OAAO1E,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnC,QAAQA,EAAE,CAACrC,KAAK;cACZ,KAAK,CAAC;gBACF,IAAI,IAAI,CAACgD,mBAAmB,IAAI,IAAI,EAAE;kBAClC;kBACA;kBACA;kBACA,IAAI,CAACA,mBAAmB,GAAG3B,MAAM,CAACyB,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,IAAI,CAACF,iBAAiB;kBACrE,IAAI,CAACI,SAAS,GACV,IAAI,CAACD,mBAAmB,GAAG,IAAI,CAACE,oBAAoB,GAAG,GAAG;gBAClE;gBACA,IAAI,CAACS,WAAW,CAACS,IAAI,CAAC;kBAAEF,8BAA8B,EAAE;gBAAG,CAAC,CAAC;gBAC7DK,sBAAsB,GAAG,IAAI,CAACJ,0BAA0B,CAAClC,IAAI,CAAC;gBAC9Db,OAAO,CAACM,iBAAiB,CAACC,GAAG,CAAC,IAAI,CAACqB,mBAAmB,CAACwB,OAAO,CAAC,CAAC,CAAC,GAAG,KAAK,IACpE,IAAI,CAACvB,SAAS,CAACuB,OAAO,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,IACzC,EAAE,GAAGD,sBAAsB,CAAC,CAAC;gBAClC,OAAO,CAAC,CAAC,CAAC,WAAWlD,MAAM,CAACgD,SAAS,CAAC,CAAC,CAAC;cAC5C,KAAK,CAAC;gBACFhC,EAAE,CAACpC,IAAI,CAAC,CAAC;gBACT,OAAO,CAAC,CAAC,CAAC,WAAW;YAC7B;UACJ,CAAC,CAAC;QACN,CAAC,CAAC;MAAE;IACR,CAAC,CAAC,IAAI,IAAI;IACV8B,KAAK,CAACkC,kBAAkB,GAAG,EAAE;IAC7B,OAAOlC,KAAK;EAChB;EACAF,aAAa,CAACpD,SAAS,CAAC0F,0BAA0B,GAAG,UAAUlC,IAAI,EAAEwC,gBAAgB,EAAE;IACnF,IAAIC,cAAc,GAAG,EAAE;IACvB,IAAIC,IAAI,GAAG1G,MAAM,CAAC0G,IAAI,CAAC1C,IAAI,CAAC,CAAC2C,IAAI,CAAC,CAAC;IACnC,KAAK,IAAIC,EAAE,GAAG,CAAC,EAAEC,MAAM,GAAGH,IAAI,EAAEE,EAAE,GAAGC,MAAM,CAAC7D,MAAM,EAAE4D,EAAE,EAAE,EAAE;MACtD,IAAIE,GAAG,GAAGD,MAAM,CAACD,EAAE,CAAC;MACpB,IAAI,IAAI,CAACG,eAAe,CAACD,GAAG,CAAC,EAAE;QAC3B,IAAI3F,KAAK,GAAG6C,IAAI,CAAC8C,GAAG,CAAC;QACrBL,cAAc,IAAIK,GAAG,GAAG,GAAG,GAAGE,wBAAwB,CAAC7F,KAAK,CAAC,GAAG,GAAG;MACvE;IACJ;IACA,IAAIqF,gBAAgB,IAAI,IAAI,IAAIC,cAAc,CAACzD,MAAM,GAAGwD,gBAAgB,EAAE;MACtE;MACA;MACAC,cAAc,GAAGA,cAAc,CAACQ,KAAK,CAAC,CAAC,EAAET,gBAAgB,GAAG,CAAC,CAAC,GAAG,KAAK;IAC1E;IACA,OAAOC,cAAc;EACzB,CAAC;EACD7C,aAAa,CAACpD,SAAS,CAACuG,eAAe,GAAG,UAAUD,GAAG,EAAE;IACrD,OAAOA,GAAG,KAAK,OAAO,IAAIA,GAAG,KAAK,MAAM;EAC5C,CAAC;EACD,OAAOlD,aAAa;AACxB,CAAC,CAACR,MAAM,CAAC8D,cAAc,CAAE;AACzB/D,OAAO,CAACS,aAAa,GAAGA,aAAa;AACrC,IAAIuD,eAAe,GAAG,CAAC;AACvB,IAAIC,sBAAsB,GAAG,CAAC;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASJ,wBAAwBA,CAACK,CAAC,EAAE;EACjC,IAAIC,aAAa,GAAGC,uBAAuB,CAACF,CAAC,CAAC;EAC9C,OAAOC,aAAa,GAAGF,sBAAsB,GACzCC,CAAC,CAACG,aAAa,CAACL,eAAe,CAAC,GAChCE,CAAC,CAACd,OAAO,CAACe,aAAa,CAAC;AAChC;AACAnE,OAAO,CAAC6D,wBAAwB,GAAGA,wBAAwB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,SAASO,uBAAuBA,CAACF,CAAC,EAAE;EAChC,IAAI,CAACI,MAAM,CAACC,QAAQ,CAACL,CAAC,CAAC,IAAIA,CAAC,KAAK,CAAC,IAAIA,CAAC,GAAG,CAAC,IAAIA,CAAC,GAAG,CAAC,CAAC,EAAE;IACnD,OAAOF,eAAe;EAC1B,CAAC,MACI;IACD,OAAOA,eAAe,GAAG5C,IAAI,CAACqB,KAAK,CAACrB,IAAI,CAACoD,KAAK,CAACpD,IAAI,CAACqD,GAAG,CAACP,CAAC,CAAC,CAAC,CAAC;EAChE;AACJ;AACAlE,OAAO,CAACoE,uBAAuB,GAAGA,uBAAuB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,IAAIM,mBAAmB,GAAG,aAAe,UAAUhE,MAAM,EAAE;EACvDjE,SAAS,CAACiI,mBAAmB,EAAEhE,MAAM,CAAC;EACtC,SAASgE,mBAAmBA,CAACC,MAAM,EAAEC,IAAI,EAAE;IACvC,IAAID,MAAM,KAAK,KAAK,CAAC,EAAE;MAAEA,MAAM,GAAG,QAAQ;IAAE;IAC5C,IAAIhE,KAAK,GAAGD,MAAM,CAACf,IAAI,CAAC,IAAI,EAAE;MAC1BwC,UAAU,EAAE,SAAAA,CAAUC,KAAK,EAAEvB,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,OAAOlC,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnC,IAAI,CAAC4D,WAAW,EAAE;YAClB,IAAI,IAAI,CAACD,IAAI,CAACE,UAAU,KAAK,OAAO,EAAE;cAClC,IAAI,CAACC,UAAU,CAAClE,IAAI,EAAE,QAAQ,EAAE,IAAI,CAACgE,WAAW,CAAC;YACrD;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACL3B,UAAU,EAAE,SAAAA,CAAU3B,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,OAAOlC,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnC,IAAI,CAAC8D,UAAU,CAAClE,IAAI,EAAE,QAAQ,EAAEU,KAAK,GAAG,CAAC,CAAC;YAC1C,IAAI,IAAI,CAACqD,IAAI,CAACI,aAAa,GAAG,CAAC,IAC3BzD,KAAK,GAAG,IAAI,CAACqD,IAAI,CAACI,aAAa,KAAK,CAAC,EAAE;cACvC,IAAI,CAACC,UAAU,CAAC1D,KAAK,CAAC;YAC1B;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACL2D,UAAU,EAAE,SAAAA,CAAUrE,IAAI,EAAE;QAAE,OAAOtD,SAAS,CAACoD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UAC9E,OAAOlC,WAAW,CAAC,IAAI,EAAE,UAAUwC,EAAE,EAAE;YACnC,IAAI,IAAI,CAACkE,WAAW,IAAI,IAAI,EAAE;cAC1B,IAAI,CAACA,WAAW,CAACC,KAAK,CAAC,CAAC;YAC5B;YACA,IAAI,IAAI,CAACC,SAAS,IAAI,IAAI,EAAE;cACxB,IAAI,CAACA,SAAS,CAACD,KAAK,CAAC,CAAC;YAC1B;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE;IACR,CAAC,CAAC,IAAI,IAAI;IACVzE,KAAK,CAACgE,MAAM,GAAGA,MAAM;IACrBhE,KAAK,CAAC2E,KAAK,GAAG,IAAI;IAClB3E,KAAK,CAACiE,IAAI,GAAGA,IAAI,IAAI,IAAI,GAAG,CAAC,CAAC,GAAGA,IAAI;IACrC,IAAIjE,KAAK,CAACiE,IAAI,CAACE,UAAU,IAAI,IAAI,EAAE;MAC/BnE,KAAK,CAACiE,IAAI,CAACE,UAAU,GAAG,OAAO;IACnC;IACA7E,MAAM,CAACyB,IAAI,CAAC6D,MAAM,CAAC,CAAC,OAAO,EAAE,OAAO,CAAC,CAACC,OAAO,CAAC7E,KAAK,CAACiE,IAAI,CAACE,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,YAAY;MAAE,OAAO,wDAAwD,IACrJ,EAAE,GAAGnE,KAAK,CAACiE,IAAI,CAACE,UAAU,CAAC;IAAE,CAAC,CAAC;IACpC,IAAInE,KAAK,CAACiE,IAAI,CAACI,aAAa,IAAI,IAAI,EAAE;MAClCrE,KAAK,CAACiE,IAAI,CAACI,aAAa,GAAG,CAAC;IAChC;IACA/E,MAAM,CAACyB,IAAI,CAAC6D,MAAM,CAACjB,MAAM,CAACmB,SAAS,CAAC9E,KAAK,CAACiE,IAAI,CAACI,aAAa,CAAC,IACzDrE,KAAK,CAACiE,IAAI,CAACI,aAAa,IAAI,CAAC,EAAE,YAAY;MAAE,OAAO,2DAA2D,IAC9G,EAAE,GAAGrE,KAAK,CAACiE,IAAI,CAACI,aAAa,CAAC;IAAE,CAAC,CAAC;IACvCrE,KAAK,CAACkE,WAAW,GAAG,CAAC;IACrB,OAAOlE,KAAK;EAChB;EACA+D,mBAAmB,CAACrH,SAAS,CAACqI,QAAQ,GAAG,UAAUJ,KAAK,EAAE;IACtD;IACA;IACA;IACA;IACA;IACA,IAAI,CAACA,KAAK,GAAGA,KAAK;EACtB,CAAC;EACDZ,mBAAmB,CAACrH,SAAS,CAAC0H,UAAU,GAAG,UAAUlE,IAAI,EAAE8E,MAAM,EAAE1H,IAAI,EAAE;IACrE,KAAK,IAAI0F,GAAG,IAAI9C,IAAI,EAAE;MAClB,IAAI8C,GAAG,KAAK,OAAO,IAAIA,GAAG,KAAK,MAAM,IAAIA,GAAG,KAAK,WAAW,EAAE;QAC1D;MACJ;MACA,IAAIiC,UAAU,GAAG,MAAM;MACvB,IAAIjC,GAAG,CAACkC,UAAU,CAACD,UAAU,CAAC,EAAE;QAC5B,IAAI,CAACE,sBAAsB,CAAC,CAAC;QAC7B,IAAIC,UAAU,GAAGJ,MAAM,GAAGhC,GAAG,CAACG,KAAK,CAAC8B,UAAU,CAAC/F,MAAM,CAAC;QACtD,IAAI,CAACwF,SAAS,CAACW,MAAM,CAACD,UAAU,EAAElF,IAAI,CAAC8C,GAAG,CAAC,EAAE1F,IAAI,CAAC;MACtD,CAAC,MACI;QACD,IAAI,CAACgI,wBAAwB,CAAC,CAAC;QAC/B,IAAI,CAACd,WAAW,CAACa,MAAM,CAAC,EAAE,GAAGL,MAAM,GAAGhC,GAAG,EAAE9C,IAAI,CAAC8C,GAAG,CAAC,EAAE1F,IAAI,CAAC;MAC/D;IACJ;EACJ,CAAC;EACDyG,mBAAmB,CAACrH,SAAS,CAAC4H,UAAU,GAAG,UAAUhH,IAAI,EAAE;IACvD,KAAK,IAAIwF,EAAE,GAAG,CAAC,EAAExC,EAAE,GAAG,IAAI,CAACqE,KAAK,CAACY,OAAO,EAAEzC,EAAE,GAAGxC,EAAE,CAACpB,MAAM,EAAE4D,EAAE,EAAE,EAAE;MAC5D,IAAIyC,OAAO,GAAGjF,EAAE,CAACwC,EAAE,CAAC;MACpB,IAAI,CAAC0B,WAAW,CAACgB,SAAS,CAACD,OAAO,CAACE,IAAI,EAAEF,OAAO,CAACG,IAAI,CAAC,CAAC,EAAEpI,IAAI,CAAC;IAClE;EACJ,CAAC;EACDyG,mBAAmB,CAACrH,SAAS,CAAC4I,wBAAwB,GAAG,YAAY;IACjE,IAAI,CAACd,WAAW,GAAG9E,aAAa,CAACiG,iBAAiB,CAACnG,IAAI,CAACoG,IAAI,CAAC,IAAI,CAAC5B,MAAM,EAAE,OAAO,CAAC,CAAC;EACvF,CAAC;EACDD,mBAAmB,CAACrH,SAAS,CAACyI,sBAAsB,GAAG,YAAY;IAC/D,IAAI,CAACT,SAAS,GAAGhF,aAAa,CAACiG,iBAAiB,CAACnG,IAAI,CAACoG,IAAI,CAAC,IAAI,CAAC5B,MAAM,EAAE,KAAK,CAAC,CAAC;EACnF,CAAC;EACD,OAAOD,mBAAmB;AAC9B,CAAC,CAACzE,MAAM,CAAC8D,cAAc,CAAE;AACzB/D,OAAO,CAAC0E,mBAAmB,GAAGA,mBAAmB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS8B,WAAWA,CAAC7B,MAAM,EAAEC,IAAI,EAAE;EAC/B,IAAID,MAAM,KAAK,KAAK,CAAC,EAAE;IAAEA,MAAM,GAAG,QAAQ;EAAE;EAC5C,OAAO,IAAID,mBAAmB,CAACC,MAAM,EAAEC,IAAI,CAAC;AAChD;AACA5E,OAAO,CAACwG,WAAW,GAAGA,WAAW"},"metadata":{},"sourceType":"script","externalDependencies":[]}